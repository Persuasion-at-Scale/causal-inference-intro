{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Design: From New Haven to Microtargeting\n",
    "\n",
    "**Class 7 | Feb 11 | Persuasion at Scale**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Persuasion-at-Scale/causal-inference-intro/blob/main/experimental-design.ipynb)\n",
    "\n",
    "**Readings:** Issenberg, *The Victory Lab* (Prologue, Ch 1, 3, 5); Gerber & Green, *Field Experiments* (Ch 1)\n",
    "\n",
    "Last time we saw *why* randomization works (potential outcomes, unbiasedness). Today we explore *how* experiments work in practice:\n",
    "\n",
    "1. **The New Haven experiment** - multi-arm trial, estimating effects of canvassing, phone, and mail\n",
    "2. **Statistical power** - why some effects are detectable and others aren't\n",
    "3. **Confounding in action** - when observational data points in the wrong direction\n",
    "4. **Microtargeting** - using predictive models to find the right voters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "BLUE = '#0072B2'\n",
    "ORANGE = '#D55E00'\n",
    "GREEN = '#009E73'\n",
    "RED = '#c0392b'\n",
    "GRAY = '#888888'\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. The New Haven Experiment\n",
    "\n",
    "In 1998, Green and Gerber randomly assigned 30,000 New Haven voters to one of four conditions:\n",
    "\n",
    "| Condition | Description | True effect (from the paper) |\n",
    "|:---|:---|:---:|\n",
    "| **Canvassing** | Yale students knock on doors, $20/hr | **+8.7 pp** |\n",
    "| **Phone calls** | Commercial call center in North Dakota | **+0.0 pp** |\n",
    "| **Direct mail** | Postcards (civic duty, community, close-election) | **+0.6 pp** |\n",
    "| **Control** | No contact | - |\n",
    "\n",
    "Let's simulate this. We'll generate voters with a baseline probability of turning out, apply the treatment effects, and see what the experiment reveals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the New Haven experiment\n",
    "N = 30000\n",
    "true_effects = {'Control': 0.0, 'Canvass': 0.087, 'Phone': 0.0, 'Mail': 0.006}\n",
    "\n",
    "# Baseline turnout probability for each voter (varies across population)\n",
    "baseline_logit = np.random.normal(-0.5, 1.0, N)  # logit scale\n",
    "baseline_prob = 1 / (1 + np.exp(-baseline_logit))  # average ~38% turnout\n",
    "\n",
    "# Random assignment: equal probability for each arm\n",
    "arms = ['Control', 'Canvass', 'Phone', 'Mail']\n",
    "assignment = np.random.choice(arms, size=N)\n",
    "\n",
    "# Generate outcomes\n",
    "effect = np.array([true_effects[a] for a in assignment])\n",
    "prob_vote = np.clip(baseline_prob + effect, 0, 1)\n",
    "voted = np.random.binomial(1, prob_vote)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'assignment': assignment,\n",
    "    'voted': voted,\n",
    "    'baseline_prob': baseline_prob\n",
    "})\n",
    "\n",
    "print(f\"Total voters: {N:,}\")\n",
    "print(f\"Per arm: ~{N//4:,}\")\n",
    "print(f\"Overall turnout: {voted.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate treatment effects (difference vs control)\n",
    "control_rate = df.loc[df['assignment'] == 'Control', 'voted'].mean()\n",
    "\n",
    "results = []\n",
    "for arm in ['Canvass', 'Phone', 'Mail']:\n",
    "    arm_data = df.loc[df['assignment'] == arm, 'voted']\n",
    "    ctrl_data = df.loc[df['assignment'] == 'Control', 'voted']\n",
    "    \n",
    "    est = arm_data.mean() - ctrl_data.mean()\n",
    "    se = np.sqrt(arm_data.var(ddof=1)/len(arm_data) + ctrl_data.var(ddof=1)/len(ctrl_data))\n",
    "    ci_lo = est - 1.96 * se\n",
    "    ci_hi = est + 1.96 * se\n",
    "    \n",
    "    results.append({\n",
    "        'Treatment': arm,\n",
    "        'Turnout': f\"{arm_data.mean():.1%}\",\n",
    "        'Estimated effect (pp)': f\"{est*100:+.1f}\",\n",
    "        'True effect (pp)': f\"{true_effects[arm]*100:+.1f}\",\n",
    "        '95% CI': f\"[{ci_lo*100:+.1f}, {ci_hi*100:+.1f}]\",\n",
    "        'Significant?': 'Yes' if abs(est/se) > 1.96 else 'No'\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"Control turnout: {control_rate:.1%}\\n\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: estimated effects with confidence intervals\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "arm_names = ['Canvass', 'Phone', 'Mail']\n",
    "colors = [GREEN, RED, BLUE]\n",
    "\n",
    "for i, arm in enumerate(arm_names):\n",
    "    arm_data = df.loc[df['assignment'] == arm, 'voted']\n",
    "    ctrl_data = df.loc[df['assignment'] == 'Control', 'voted']\n",
    "    est = arm_data.mean() - ctrl_data.mean()\n",
    "    se = np.sqrt(arm_data.var(ddof=1)/len(arm_data) + ctrl_data.var(ddof=1)/len(ctrl_data))\n",
    "    \n",
    "    ax.errorbar(est * 100, i, xerr=1.96*se*100, fmt='o', color=colors[i],\n",
    "                markersize=12, capsize=8, capthick=2, linewidth=2)\n",
    "    # True effect marker\n",
    "    ax.plot(true_effects[arm]*100, i, 's', color=colors[i], markersize=10,\n",
    "            markeredgecolor='black', markeredgewidth=1.5, alpha=0.5)\n",
    "\n",
    "ax.axvline(0, color='black', linewidth=1, linestyle='-')\n",
    "ax.set_yticks(range(3))\n",
    "ax.set_yticklabels(arm_names, fontsize=14)\n",
    "ax.set_xlabel('Effect on turnout (percentage points)', fontsize=13)\n",
    "ax.set_title('New Haven Experiment: Treatment Effects\\n(circles = estimates with 95% CI, squares = true effects)', fontsize=13)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Canvassing has a clear, large effect.\")\n",
    "print(\"Phone calls: indistinguishable from zero.\")\n",
    "print(\"Mail: tiny effect, hard to detect even with 30,000 voters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Notice that the **mail effect** (+0.6 pp) is real but almost impossible to detect, even with ~7,500 voters per arm. The confidence interval is wide relative to the effect.\n",
    "\n",
    "This raises a critical question: *how many subjects do you need to reliably detect an effect of a given size?* That's the question of **statistical power**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Statistical Power\n",
    "\n",
    "**Power** = the probability that your experiment correctly detects a real effect (rejects H0 when H0 is false).\n",
    "\n",
    "Power depends on three things:\n",
    "- **Effect size**: bigger effects are easier to detect\n",
    "- **Sample size (N)**: more data = more precision\n",
    "- **Variance**: noisier outcomes require more data\n",
    "\n",
    "The conventional target is 80% power: you want at least an 80% chance of detecting the effect if it's real.\n",
    "\n",
    "Let's compute power curves for the three New Haven treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_power(effect_size, n_per_arm, baseline_rate=0.38, n_sims=2000):\n",
    "    \"\"\"Simulate experiments and compute the fraction that reject H0.\"\"\"\n",
    "    significant = 0\n",
    "    for _ in range(n_sims):\n",
    "        control = np.random.binomial(1, baseline_rate, n_per_arm)\n",
    "        treated = np.random.binomial(1, baseline_rate + effect_size, n_per_arm)\n",
    "        diff = treated.mean() - control.mean()\n",
    "        se = np.sqrt(treated.var(ddof=1)/n_per_arm + control.var(ddof=1)/n_per_arm)\n",
    "        if se > 0 and abs(diff / se) > 1.96:\n",
    "            significant += 1\n",
    "    return significant / n_sims\n",
    "\n",
    "# Power curves for each effect size\n",
    "sample_sizes = [100, 250, 500, 1000, 2500, 5000, 7500, 10000, 25000, 50000]\n",
    "effects = {\n",
    "    'Canvass (+8.7 pp)': 0.087,\n",
    "    'Mail (+0.6 pp)': 0.006,\n",
    "    'Phone (+0.0 pp)': 0.001,  # tiny effect to show flat line\n",
    "}\n",
    "\n",
    "print(\"Computing power curves (this takes ~30 seconds)...\")\n",
    "power_results = {}\n",
    "for label, eff in effects.items():\n",
    "    powers = [compute_power(eff, n) for n in sample_sizes]\n",
    "    power_results[label] = powers\n",
    "    print(f\"  {label}: done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors_power = {'Canvass (+8.7 pp)': GREEN, 'Mail (+0.6 pp)': BLUE, 'Phone (+0.0 pp)': RED}\n",
    "\n",
    "for label, powers in power_results.items():\n",
    "    ax.plot(sample_sizes, powers, 'o-', color=colors_power[label], label=label,\n",
    "            linewidth=2, markersize=6)\n",
    "\n",
    "ax.axhline(0.8, color=GRAY, linestyle='--', linewidth=1.5, label='80% power target')\n",
    "ax.axhline(0.05, color=GRAY, linestyle=':', linewidth=1, alpha=0.5)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Sample size per arm', fontsize=13)\n",
    "ax.set_ylabel('Power (probability of detecting the effect)', fontsize=13)\n",
    "ax.set_title('Power Curves: How Many Voters Do You Need?', fontsize=14)\n",
    "ax.set_ylim(-0.02, 1.05)\n",
    "ax.legend(fontsize=12, loc='center right')\n",
    "ax.set_xticks(sample_sizes)\n",
    "ax.set_xticklabels([f\"{n:,}\" for n in sample_sizes], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Canvassing: detectable with just a few hundred voters per arm.\")\n",
    "print(\"Mail: you need TENS OF THOUSANDS to reliably detect a 0.6 pp effect.\")\n",
    "print(\"This is why Green & Gerber needed 30,000 voters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The power lesson\n",
    "\n",
    "Campaigns spend billions on tactics with *tiny* effect sizes. Detecting those effects requires *enormous* experiments. This is why political science went decades without field experiments: the logistics of randomizing thousands of voters seemed impossible.\n",
    "\n",
    "> \"No one has any idea of the value of the ad versus a phone call from a friend.\" - Samuel Popkin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 3. Confounding in Action\n\nGerber & Green Ch 1 emphasize that correlations can be \"a misleading guide to causality.\" Here's a classic example from medicine:\n\n**Which hospital is better?** Hospital A (a community hospital) has a 95% survival rate. Hospital B (a major teaching hospital) has only 85% survival. Should you go to Hospital A?\n\nNot so fast. Hospital B treats the sickest patients - complex surgeries, rare cancers, emergency transfers. Hospital A mostly handles routine cases. The *patient mix* is a confounder: it drives both hospital choice and outcomes.\n\nLet's simulate this and see how badly observational data misleads us."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simulate the hospital confounding example\nN_patients = 1000\n\n# Patient severity (the confounder) - higher = sicker\nseverity = np.random.exponential(3, N_patients)\n\n# Hospital selection: sicker patients go to Hospital B (the teaching hospital)\n# This is NOT random - it's driven by severity\np_hospital_B = 1 / (1 + np.exp(-(severity - 4)))  # sicker -> more likely B\nwent_to_B = np.random.binomial(1, p_hospital_B)\n\n# TRUE EFFECT of Hospital B: IMPROVES survival by 5 percentage points\n# (better doctors, better equipment, more resources)\nTRUE_HOSPITAL_EFFECT = 0.05\n\n# Survival depends on severity (negatively) and hospital quality (positively)\nbaseline_survival = 1 / (1 + np.exp(0.5 * severity - 2))  # sicker -> lower survival\nsurvival_prob = np.clip(baseline_survival + TRUE_HOSPITAL_EFFECT * went_to_B, 0, 1)\nsurvived = np.random.binomial(1, survival_prob)\n\npatients = pd.DataFrame({\n    'severity': severity,\n    'hospital': np.where(went_to_B, 'B (teaching)', 'A (community)'),\n    'went_to_B': went_to_B,\n    'survived': survived\n})\n\n# Naive observational comparison\nsurv_A = patients.loc[patients['went_to_B']==0, 'survived'].mean()\nsurv_B = patients.loc[patients['went_to_B']==1, 'survived'].mean()\nobs_diff = surv_B - surv_A\n\nprint(\"Observational comparison:\")\nprint(f\"  Hospital A (community) survival: {surv_A:.1%}\")\nprint(f\"  Hospital B (teaching)  survival: {surv_B:.1%}\")\nprint(f\"  Naive estimate (B - A):          {obs_diff:+.1%}\")\nprint(f\"  True causal effect of B:         {TRUE_HOSPITAL_EFFECT:+.1%}\")\nprint(f\"\\nThe naive estimate has the WRONG SIGN!\")\nprint(f\"Hospital B looks WORSE, but it's actually BETTER.\")\nprint(f\"The confounder (patient severity) drives both hospital choice and outcomes.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Panel 1: The misleading observational picture\nax = axes[0]\ncolors_h = [RED if b else BLUE for b in patients['went_to_B']]\nax.scatter(patients['severity'], patients['survived'] + np.random.normal(0, 0.02, N_patients),\n           c=colors_h, alpha=0.3, s=30)\nax.scatter([], [], c=BLUE, label='Hospital A (community)', s=60)\nax.scatter([], [], c=RED, label='Hospital B (teaching)', s=60)\n\n# Show severity distributions\nax2 = ax.twinx()\nsev_A = patients.loc[patients['went_to_B']==0, 'severity']\nsev_B = patients.loc[patients['went_to_B']==1, 'severity']\nax2.hist(sev_A, bins=20, alpha=0.2, color=BLUE, density=True)\nax2.hist(sev_B, bins=20, alpha=0.2, color=RED, density=True)\nax2.set_ylabel('Density of patients', fontsize=10, color=GRAY)\nax2.tick_params(axis='y', labelcolor=GRAY)\n\nax.set_xlabel('Patient severity', fontsize=12)\nax.set_ylabel('Survived (0/1, jittered)', fontsize=12)\nax.set_title('Selection bias: sicker patients go to Hospital B', fontsize=12)\nax.legend(fontsize=11, loc='center right')\n\n# Panel 2: What a randomized trial would show\nax = axes[1]\nrandom_B = np.random.binomial(1, 0.5, N_patients)\nsurvival_prob_rct = np.clip(baseline_survival + TRUE_HOSPITAL_EFFECT * random_B, 0, 1)\nsurvived_rct = np.random.binomial(1, survival_prob_rct)\n\nrct_A = survived_rct[random_B == 0].mean()\nrct_B = survived_rct[random_B == 1].mean()\nrct_diff = rct_B - rct_A\n\nx_pos = [0, 1]\nbars = ax.bar(x_pos, [surv_A, surv_B], color=[BLUE, RED], width=0.35,\n              label='Observational', alpha=0.4)\nbars2 = ax.bar([x + 0.35 for x in x_pos], [rct_A, rct_B], color=[BLUE, RED], width=0.35,\n               label='Randomized', edgecolor='black', linewidth=1.5)\n\nax.set_xticks([0.175, 1.175])\nax.set_xticklabels(['Hospital A', 'Hospital B'], fontsize=13)\nax.set_ylabel('Survival rate', fontsize=12)\nax.set_title(f'Observational: B looks worse (diff={obs_diff:+.1%})\\n'\n             f'Randomized: B is actually better (diff={rct_diff:+.1%})', fontsize=12)\nax.legend(fontsize=11)\nax.set_ylim(0, 1.1)\n\n# Annotate\nfor bar in bars:\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n            f'{bar.get_height():.0%}', ha='center', fontsize=11, color=GRAY)\nfor bar in bars2:\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n            f'{bar.get_height():.0%}', ha='center', fontsize=11, fontweight='bold')\n\nplt.suptitle('Confounding: Why Observational Data Can Point in the Wrong Direction',\n             fontsize=14, fontweight='bold', y=1.03)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### The basketball analogy\n\n> \"Basketball players tend to be taller than other people, but you cannot grow taller by joining the basketball team.\" - Gerber & Green\n\nHospital B has lower survival rates - but you cannot worsen your health by going there. The hospital and the outcome share a common cause (patient severity), and the correlation between hospital choice and survival reflects that common cause, not the hospital's quality.\n\nGerber & Green call the list of possible confounders \"a bottomless pit\" with \"no well-defined stopping rule.\" You can try to control for severity, but what about insurance status, distance to hospital, time of day, referring physician...?\n\nThis is precisely why Fisher's insight was so important: **random assignment** severs the link between treatment and all confounders, observed or not."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Microtargeting: Finding the Right Voters\n",
    "\n",
    "Issenberg (Ch 5) describes Alex Gage's breakthrough: merging consumer data (Acxiom) with voter files to predict political leanings from shopping behavior.\n",
    "\n",
    "> \"HBO subscription predicted openness to Romney.\" - Issenberg\n",
    "\n",
    "The idea: instead of targeting by geography (all voters in a precinct), target by individual. Build a model that predicts who's persuadable, then concentrate resources on those people.\n",
    "\n",
    "Let's simulate this. We'll generate a population of voters with consumer attributes and political preferences, build a simple model, and see how targeted outreach compares to broadcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate voter population with consumer data\n",
    "N_voters = 5000\n",
    "\n",
    "# Consumer variables (a la Acxiom)\n",
    "income = np.random.lognormal(10.5, 0.6, N_voters)  # household income\n",
    "has_hbo = np.random.binomial(1, 0.3, N_voters)\n",
    "college_grad = np.random.binomial(1, 0.35, N_voters)\n",
    "attends_church = np.random.binomial(1, 0.25, N_voters)\n",
    "drives_pickup = np.random.binomial(1, 0.15, N_voters)\n",
    "reads_nyt = np.random.binomial(1, 0.12, N_voters)\n",
    "age = np.random.normal(45, 15, N_voters).clip(18, 90)\n",
    "\n",
    "# Latent political leaning (higher = more conservative)\n",
    "# These weights are made up but directionally plausible\n",
    "leaning = (\n",
    "    0.3 * (income > 80000).astype(float)\n",
    "    - 0.4 * has_hbo\n",
    "    + 0.5 * attends_church\n",
    "    + 0.6 * drives_pickup\n",
    "    - 0.5 * reads_nyt\n",
    "    - 0.3 * college_grad\n",
    "    + 0.01 * (age - 45)\n",
    "    + np.random.normal(0, 0.8, N_voters)\n",
    ")\n",
    "\n",
    "# Binary: supports our candidate (say, a moderate Republican like Romney 2002)\n",
    "p_support = 1 / (1 + np.exp(-leaning))\n",
    "supports_candidate = np.random.binomial(1, p_support)\n",
    "\n",
    "voters = pd.DataFrame({\n",
    "    'income': income,\n",
    "    'has_hbo': has_hbo,\n",
    "    'college_grad': college_grad,\n",
    "    'attends_church': attends_church,\n",
    "    'drives_pickup': drives_pickup,\n",
    "    'reads_nyt': reads_nyt,\n",
    "    'age': age,\n",
    "    'supports_candidate': supports_candidate\n",
    "})\n",
    "\n",
    "print(f\"Voter population: {N_voters:,}\")\n",
    "print(f\"Support rate: {supports_candidate.mean():.1%}\")\n",
    "print(f\"\\nConsumer variable correlations with support:\")\n",
    "features = ['has_hbo', 'college_grad', 'attends_church', 'drives_pickup', 'reads_nyt']\n",
    "for feat in features:\n",
    "    rate_1 = voters.loc[voters[feat]==1, 'supports_candidate'].mean()\n",
    "    rate_0 = voters.loc[voters[feat]==0, 'supports_candidate'].mean()\n",
    "    print(f\"  {feat:20s}: {rate_1:.1%} vs {rate_0:.1%}  (diff: {rate_1-rate_0:+.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a predictive model (like Gage did for Bush 2004)\n",
    "feature_cols = ['has_hbo', 'college_grad', 'attends_church', 'drives_pickup', 'reads_nyt', 'age']\n",
    "X = voters[feature_cols].values\n",
    "y = voters['supports_candidate'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicted probabilities\n",
    "voters['predicted_support'] = model.predict_proba(X)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(f\"Model AUC: {auc:.3f}\\n\")\n",
    "\n",
    "print(\"Feature importances (logistic regression coefficients):\")\n",
    "for feat, coef in sorted(zip(feature_cols, model.coef_[0]), key=lambda x: -abs(x[1])):\n",
    "    direction = 'more likely' if coef > 0 else 'less likely'\n",
    "    print(f\"  {feat:20s}: {coef:+.3f}  ({direction} to support)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare targeted vs untargeted outreach\n",
    "# Scenario: you can canvass 500 voters (10% of population)\n",
    "# Canvassing effect: +8.7 pp turnout among supporters\n",
    "BUDGET = 500\n",
    "CANVASS_EFFECT = 0.087\n",
    "\n",
    "# Baseline turnout (everyone has ~50% chance of voting)\n",
    "voters['baseline_turnout'] = np.random.uniform(0.3, 0.7, N_voters)\n",
    "\n",
    "# Strategy 1: Random (broadcast) - canvass 500 random voters\n",
    "random_targets = np.random.choice(N_voters, BUDGET, replace=False)\n",
    "random_contacted_supporters = voters.iloc[random_targets]['supports_candidate'].sum()\n",
    "\n",
    "# Strategy 2: Targeted - canvass the 500 voters most likely to be supporters\n",
    "targeted_idx = voters['predicted_support'].nlargest(BUDGET).index\n",
    "targeted_contacted_supporters = voters.iloc[targeted_idx]['supports_candidate'].sum()\n",
    "\n",
    "# Expected additional votes from each strategy\n",
    "# (only supporters who are contacted AND whose turnout is flipped by canvassing)\n",
    "random_extra_votes = random_contacted_supporters * CANVASS_EFFECT\n",
    "targeted_extra_votes = targeted_contacted_supporters * CANVASS_EFFECT\n",
    "\n",
    "print(\"Canvassing budget: 500 door knocks\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nRandom targeting:\")\n",
    "print(f\"  Supporters contacted: {random_contacted_supporters} / {BUDGET}\")\n",
    "print(f\"  Expected extra votes: {random_extra_votes:.1f}\")\n",
    "print(f\"\\nMicrotargeting:\")\n",
    "print(f\"  Supporters contacted: {targeted_contacted_supporters} / {BUDGET}\")\n",
    "print(f\"  Expected extra votes: {targeted_extra_votes:.1f}\")\n",
    "print(f\"\\nMicrotargeting advantage: {targeted_extra_votes/random_extra_votes:.1f}x more effective\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the targeting advantage\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Distribution of predicted support scores\n",
    "ax = axes[0]\n",
    "ax.hist(voters.loc[voters['supports_candidate']==1, 'predicted_support'],\n",
    "        bins=30, alpha=0.6, color=BLUE, label='Actual supporters', density=True)\n",
    "ax.hist(voters.loc[voters['supports_candidate']==0, 'predicted_support'],\n",
    "        bins=30, alpha=0.6, color=ORANGE, label='Non-supporters', density=True)\n",
    "threshold = voters['predicted_support'].nlargest(BUDGET).min()\n",
    "ax.axvline(threshold, color='black', linestyle='--', linewidth=2,\n",
    "           label=f'Top {BUDGET} threshold')\n",
    "ax.set_xlabel('Predicted support probability', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Model separates supporters from non-supporters', fontsize=12)\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "# Panel 2: Efficiency comparison\n",
    "ax = axes[1]\n",
    "strategies = ['Random\\n(broadcast)', 'Microtargeted']\n",
    "supporter_rates = [\n",
    "    random_contacted_supporters / BUDGET * 100,\n",
    "    targeted_contacted_supporters / BUDGET * 100\n",
    "]\n",
    "bars = ax.bar(strategies, supporter_rates, color=[GRAY, GREEN], width=0.5)\n",
    "for bar, rate in zip(bars, supporter_rates):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "            f'{rate:.0f}%', ha='center', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('% of contacted voters who are supporters', fontsize=12)\n",
    "ax.set_title('Microtargeting concentrates resources on supporters', fontsize=12)\n",
    "ax.set_ylim(0, 105)\n",
    "\n",
    "plt.suptitle('\"Without the ability to find 3 people out of 10 on a block,\\nwe would have had to knock on all 10 doors.\" - Matthew Dowd',\n",
    "             fontsize=12, style='italic', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. The Full Picture: Experiments + Microtargeting\n",
    "\n",
    "The arc of the readings:\n",
    "\n",
    "1. **Experiments** tell you *what works* (canvassing >> phone calls)\n",
    "2. **Microtargeting** tells you *who to reach* (find likely supporters from consumer data)\n",
    "3. **The combination** is modern evidence-based campaigning\n",
    "\n",
    "Let's put it together: what if you could run an experiment *within* each microtargeting segment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heterogeneous treatment effects: canvassing works better on some voters\n",
    "# Suppose persuadable voters (predicted support ~0.4-0.6) respond MORE to canvassing\n",
    "\n",
    "N_exp2 = 2000\n",
    "predicted_scores = voters['predicted_support'].values[:N_exp2]\n",
    "\n",
    "# Treatment effect varies: highest for \"on the fence\" voters\n",
    "# (those with predicted support near 0.5)\n",
    "persuadability = 1 - 4 * (predicted_scores - 0.5)**2  # peaks at 0.5\n",
    "individual_effect = 0.15 * persuadability  # up to 15 pp for most persuadable\n",
    "\n",
    "# Run an experiment\n",
    "treat_exp = np.random.binomial(1, 0.5, N_exp2)\n",
    "baseline_turnout = np.random.uniform(0.3, 0.6, N_exp2)\n",
    "turnout = np.random.binomial(1, np.clip(baseline_turnout + individual_effect * treat_exp, 0, 1))\n",
    "\n",
    "# Estimate effects by predicted support tercile\n",
    "exp_df = pd.DataFrame({\n",
    "    'predicted_support': predicted_scores,\n",
    "    'treated': treat_exp,\n",
    "    'voted': turnout,\n",
    "    'persuadability': persuadability\n",
    "})\n",
    "exp_df['segment'] = pd.qcut(exp_df['predicted_support'], 3,\n",
    "                             labels=['Unlikely supporter', 'Persuadable', 'Likely supporter'])\n",
    "\n",
    "print(\"Treatment effects by voter segment:\\n\")\n",
    "for seg in ['Unlikely supporter', 'Persuadable', 'Likely supporter']:\n",
    "    seg_data = exp_df[exp_df['segment'] == seg]\n",
    "    treat_rate = seg_data.loc[seg_data['treated']==1, 'voted'].mean()\n",
    "    ctrl_rate = seg_data.loc[seg_data['treated']==0, 'voted'].mean()\n",
    "    effect = treat_rate - ctrl_rate\n",
    "    n = len(seg_data)\n",
    "    print(f\"  {seg:22s}  (N={n:4d}):  effect = {effect:+.1%}\")\n",
    "\n",
    "overall = exp_df.loc[exp_df['treated']==1, 'voted'].mean() - exp_df.loc[exp_df['treated']==0, 'voted'].mean()\n",
    "print(f\"\\n  {'Overall':22s}  (N={N_exp2:4d}):  effect = {overall:+.1%}\")\n",
    "print(\"\\nThe overall average masks variation across segments.\")\n",
    "print(\"Campaigns that can identify persuadable voters get more bang per door knock.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Summary\n\n| Concept | Key takeaway |\n|:---|:---|\n| **Multi-arm experiments** | Different treatments have vastly different effects (8.7 pp vs 0 pp) |\n| **Statistical power** | Small effects need large experiments - this is why campaign experiments were rare before 1998 |\n| **Confounding** | Observational data can point in the WRONG DIRECTION (hospital example) |\n| **Microtargeting** | Predictive models from consumer data concentrate resources on the right voters |\n| **The combination** | Experiments identify what works; microtargeting identifies who to reach |\n\n**Next:** HW2 - designing your own experiment"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}